name: CI and Native Build

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

jobs:
  setup-and-ci:
    name: Setup and CI Checks
    runs-on: ubuntu-latest
    outputs:
      status: ${{ job.status }}
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4
        with:
          submodules: false  # We'll handle llama.cpp setup with our scripts
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22'
          cache: 'npm'
      
      - name: Install Dependencies
        run: npm ci
        # This automatically sets up llama.cpp through the postinstall script
      
      - name: TypeScript Check
        run: npm run typescript
      
      - name: Lint
        run: npm run lint
      
      - name: Build
        run: npm run prepare
      
      - name: Run Tests
        run: npm test
      
      # Upload the whole repository in its current state for other jobs to use
      - name: Upload Repository State
        uses: actions/upload-artifact@v4
        with:
          name: repo-state
          path: .
          retention-days: 1
  
  android-build:
    name: Android Native Build
    needs: setup-and-ci
    runs-on: ubuntu-latest
    steps:
      - name: Download Repository
        uses: actions/download-artifact@v4
        with:
          name: repo-state
          path: .
      
      - name: Restore file permissions
        run: |
          chmod +x scripts/*.sh
          find android -name "*.sh" -exec chmod +x {} \; || true
          find android -name "gradlew" -exec chmod +x {} \; || true
      
      - name: Setup Java
        uses: actions/setup-java@v4
        with:
          distribution: 'zulu'
          java-version: '17'
      
      - name: Setup Android SDK
        uses: android-actions/setup-android@v3
        with:
          packages: 'platforms;android-35 build-tools;35.0.0 ndk;27.2.12479018 cmake;3.22.1'
          accept-android-sdk-licenses: true
      
      - name: Create prebuilt directory
        run: mkdir -p prebuilt
      
      - name: Initialize llama.cpp for Android
        run: |
          echo "Initializing llama.cpp for Android platform only..."
          scripts/setupLlamaCpp.sh init --platform=android
      
      - name: Build GPU Libraries
        run: |
          # Get Android NDK path
          NDK_PATH=$ANDROID_HOME/ndk/27.2.12479018
          
          # Check if Vulkan SDK components are needed
          if ! command -v glslc &>/dev/null; then
            echo "Vulkan SDK components not found, installing minimal requirements..."
            
            # Check if we now have glslc
            if command -v glslc &>/dev/null; then
              GLSLC_PATH=$(which glslc)
              echo "✅ Found glslc at: $GLSLC_PATH"
            else
              echo "⚠️ glslc not found after installation, will use pre-built shaders"
              GLSLC_PATH=""
            fi
          else
            GLSLC_PATH=$(which glslc)
            echo "✅ Found glslc at: $GLSLC_PATH"
          fi
          
          # First build the GPU backend libraries
          echo "Building Android GPU backend libraries..."
          if [ -n "$GLSLC_PATH" ]; then
            scripts/build_android_gpu_backend.sh --abi=all --ndk-path="$NDK_PATH" --glslc-path="$GLSLC_PATH" --platform=android
          else
            scripts/build_android_gpu_backend.sh --abi=all --ndk-path="$NDK_PATH" --platform=android
          fi
          
          # Verify GPU libraries were built in prebuilt directory
          if [ -d "prebuilt/gpu/arm64-v8a" ] && [ "$(ls -A prebuilt/gpu/arm64-v8a/ 2>/dev/null)" ]; then
            echo "✅ Successfully built GPU libraries for arm64-v8a"
            ls -la prebuilt/gpu/arm64-v8a/
          else
            echo "⚠️ No GPU libraries found for arm64-v8a, build may have failed"
            # Don't fail the workflow, as we'll still try to build with CPU-only
          fi
          
          if [ -d "prebuilt/gpu/x86_64" ] && [ "$(ls -A prebuilt/gpu/x86_64/ 2>/dev/null)" ]; then
            echo "✅ Successfully built GPU libraries for x86_64"
            ls -la prebuilt/gpu/x86_64/
          else
            echo "⚠️ No GPU libraries found for x86_64, build may have failed"
            # Don't fail the workflow, as we'll still try to build with CPU-only
          fi
      
      - name: Build Final Android Libraries
        run: |
          # Get Android NDK path (same as above)
          NDK_PATH=$ANDROID_HOME/ndk/27.2.12479018
          
          # Now build the final Android libraries incorporating the GPU backends
          echo "Building Android libraries with OpenCL and Vulkan support..."
          scripts/build_android_external.sh --abi=all --ndk-path="$NDK_PATH" --platform=android
          
          # Verify libraries were built successfully
          if [ ! -f "android/src/main/jniLibs/arm64-v8a/libllama.so" ]; then
            echo "❌ Failed to build arm64-v8a library"
            exit 1
          else
            echo "✅ Successfully built arm64-v8a library"
            # Verify library is not empty
            if [ ! -s "android/src/main/jniLibs/arm64-v8a/libllama.so" ]; then
              echo "⚠️ arm64-v8a library is empty"
              exit 1
            fi
          fi
          
          if [ ! -f "android/src/main/jniLibs/x86_64/libllama.so" ]; then
            echo "❌ Failed to build x86_64 library"
            exit 1
          else
            echo "✅ Successfully built x86_64 library"
            # Verify library is not empty
            if [ ! -s "android/src/main/jniLibs/x86_64/libllama.so" ]; then
              echo "⚠️ x86_64 library is empty"
              exit 1
            fi
          fi
          
          # Check for GPU capability flags
          if [ -f "android/src/main/jniLibs/arm64-v8a/.opencl_enabled" ]; then
            echo "✅ OpenCL support enabled for arm64-v8a"
          else
            echo "⚠️ OpenCL support not enabled for arm64-v8a"
          fi
          
          if [ -f "android/src/main/jniLibs/arm64-v8a/.vulkan_enabled" ]; then
            echo "✅ Vulkan support enabled for arm64-v8a"
          else
            echo "⚠️ Vulkan support not enabled for arm64-v8a"
          fi
      
      - name: Verify Library Architecture and Symbols
        run: |
          # Detailed verification of the final libraries
          echo "Checking for GPU backend support and architecture correctness..."
          
          # Check x86_64 capability flags
          echo "Checking x86_64 library for GPU support:"
          if [ -f "android/src/main/jniLibs/x86_64/.opencl_enabled" ]; then
            echo "✅ OpenCL support enabled in x86_64 library"
          else
            echo "❌ No OpenCL support detected in x86_64 library"
          fi
          
          if [ -f "android/src/main/jniLibs/x86_64/.vulkan_enabled" ]; then
            echo "✅ Vulkan support enabled in x86_64 library"
          else
            echo "❌ No Vulkan support detected in x86_64 library"
          fi
          
          # Verify that the main libraries exist and contain GPU symbols
          if [ -f "android/src/main/jniLibs/arm64-v8a/libllama.so" ]; then
            echo "Checking for GPU symbols in the main arm64-v8a library:"
            
            # Check for OpenCL and Vulkan symbols in the actual libllama.so
            if nm -D android/src/main/jniLibs/arm64-v8a/libllama.so | grep -i "opencl" >/dev/null; then
              echo "✅ OpenCL symbols found in arm64-v8a libllama.so"
            else
              echo "⚠️ No OpenCL symbols found in arm64-v8a libllama.so - this is expected if the GPU backend is dynamically loaded"
            fi
            
            if nm -D android/src/main/jniLibs/arm64-v8a/libllama.so | grep -i -E "vulkan|vk_|ggml.*vulkan" >/dev/null; then
              echo "✅ Vulkan symbols found in arm64-v8a libllama.so"
            else
              echo "⚠️ No Vulkan symbols found in arm64-v8a libllama.so - this is expected if the GPU backend is dynamically loaded"
            fi
            
            # Check if GPU defines are in the binary
            if strings android/src/main/jniLibs/arm64-v8a/libllama.so | grep -i -E "LLAMACPPRN_OPENCL_ENABLED=1|LLAMACPPRN_VULKAN_ENABLED=1" >/dev/null; then
              echo "✅ GPU capability flags found in arm64-v8a binary"
            else
              echo "⚠️ No GPU capability flags found in arm64-v8a binary"
            fi
          else
            echo "❌ Main library libllama.so not found for arm64-v8a"
          fi
          
          # Check for architecture-specific correctness
          if [ -f "android/src/main/jniLibs/arm64-v8a/libllama.so" ]; then
            file_output=$(file "android/src/main/jniLibs/arm64-v8a/libllama.so")
            if echo "$file_output" | grep -q "aarch64"; then
              echo "✅ arm64-v8a library is correctly built for aarch64 architecture"
            else
              echo "❌ arm64-v8a library is NOT built for aarch64 architecture: $file_output"
            fi
          fi
          
          if [ -f "android/src/main/jniLibs/x86_64/libllama.so" ]; then
            file_output=$(file "android/src/main/jniLibs/x86_64/libllama.so")
            if echo "$file_output" | grep -q "x86-64"; then
              echo "✅ x86_64 library is correctly built for x86-64 architecture"
            else
              echo "❌ x86_64 library is NOT built for x86-64 architecture: $file_output"
            fi
          fi
      
      - name: Upload Android Native Libs
        uses: actions/upload-artifact@v4
        with:
          name: android-native-libs
          path: android/src/main/jniLibs/
  
  ios-build:
    name: iOS Native Build
    needs: setup-and-ci
    runs-on: macos-latest
    steps:
      - name: Download Repository
        uses: actions/download-artifact@v4
        with:
          name: repo-state
          path: .
      
      - name: Restore file permissions
        run: |
          chmod +x scripts/*.sh
      
      - name: Setup iOS Framework
        run: |
          # Initialize the llama.cpp repository if needed
          scripts/setupLlamaCpp.sh init
          
          # Use the build_apple_external.sh to set up iOS framework
          scripts/build_apple_external.sh init
          
          # Verify the iOS xcframework was set up correctly
          if [ ! -d "ios/libs/llama.xcframework" ]; then
            echo "❌ iOS framework build failed!"
            exit 1
          else
            echo "✅ iOS framework downloaded successfully"
            
            # List available slices
            echo "Available iOS framework slices:"
            ls -la ios/libs/llama.xcframework/
          fi
          
      - name: Upload iOS Framework
        uses: actions/upload-artifact@v4
        with:
          name: ios-framework
          path: ios/libs/llama.xcframework/
          
      - name: Validate iOS Podspec
        run: |
          # Check if the podspec exists
          if [ ! -f "LlamaCppRn.podspec" ]; then
            echo "❌ LlamaCppRn.podspec not found"
            exit 1
          fi
          
          # Just check the podspec content without running validation
          if grep -q "s.vendored_frameworks" LlamaCppRn.podspec && 
             grep -q "install_modules_dependencies" LlamaCppRn.podspec; then
            echo "✅ Podspec contains required sections including Turbo Module dependencies"
          else
            echo "❌ Podspec is missing required sections"
            exit 1
          fi
          
          echo "✅ iOS library setup validated"
  
  # Create final artifact for subsequent workflows
  create-workflow-artifact:
    name: Create Workflow Artifact
    if: ${{ success() }}
    needs: [setup-and-ci, android-build, ios-build]
    runs-on: ubuntu-latest
    steps:
      - name: Download Repository
        uses: actions/download-artifact@v4
        with:
          name: repo-state
          path: .
          
      - name: Download Android Libraries
        uses: actions/download-artifact@v4
        with:
          name: android-native-libs
          path: android/src/main/jniLibs/
          
      - name: Download iOS Framework
        uses: actions/download-artifact@v4
        with:
          name: ios-framework
          path: ios/libs/llama.xcframework/
      
      - name: Restore file permissions
        run: |
          chmod +x scripts/*.sh
          find android -name "*.sh" -exec chmod +x {} \; || true
          find android -name "gradlew" -exec chmod +x {} \; || true
      
      # Upload a single combined artifact with everything needed for the next workflows
      - name: Upload Complete Artifact
        uses: actions/upload-artifact@v4
        with:
          name: llamacpp-rn-complete
          path: |
            cpp/
            ios/
            android/
            lib/
            node_modules/
            LlamaCppRn.podspec
            package.json
            tsconfig.json
            tsconfig.build.json
            scripts/
  
  build-success:
    name: CI and Native Build Success
    needs: [setup-and-ci, android-build, ios-build, create-workflow-artifact]
    runs-on: ubuntu-latest
    if: ${{ always() }}
    steps:
      - name: Check Status
        run: |
          if [ "${{ needs.setup-and-ci.result }}" = "success" ] && [ "${{ needs.android-build.result }}" = "success" ] && [ "${{ needs.ios-build.result }}" = "success" ] && [ "${{ needs.create-workflow-artifact.result }}" = "success" ]; then
            echo "All CI and Native Build steps passed!"
            exit 0
          else
            echo "One or more steps failed!"
            exit 1
          fi 
